<h1 align = 'center'> <font color = black face=雅黑>第一课：书生·浦语全链路开源体系</font></h1>

# 课程信息

- 讲师：陈恺，上海人工智能实验室青年科学家
- 课时：36分23秒
- 课程链接：[书生·浦语大模型全链路开源体系_哔哩哔哩_](https://www.bilibili.com/video/BV1Vx421X72D/?vd_source=a54da2b96cb46916e198eb5ccec81669)

# 1.开源历程

![image-20240329185036180](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329185036180.png)

## 1.1 InternLM2的体系

![image-20240329185143208](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329185143208.png)

## 1.2 回归语言建模的本质

大模型本质上在做语言建模，通过高质量预料，让模型学会更好的建模能力。

![image-20240329185639525](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329185639525.png)

## 1.3 主要亮点

![image-20240329185753181](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329185753181.png)

> 大模型中的代码解释器的作用是执行和解释代码。通过结合代码解释器，大模型可以对数学和代码的推理进行增强的原因如下：
>
> 1. **语言理解和生成**：代码解释器使大模型能够理解和生成各种编程语言的代码。这种能力使得大模型可以处理各种复杂的编程任务，包括代码补全、自动生成代码等。
> 2. **程序理解和执行**：大模型通过代码解释器能够理解程序的逻辑结构和执行过程。这样，它可以更好地推断出程序的行为，包括变量的赋值、函数的调用等，从而提高对代码执行流程的理解。
> 3. **数学推理**：结合代码解释器，大模型可以执行数学运算并进行推理。例如，在执行机器学习模型时，大模型可以使用数学运算来进行前向传播和反向传播，从而进行模型训练和推断。
> 4. **代码生成**：代码解释器使得大模型能够生成各种类型的代码，包括程序、脚本等。这种能力对于自动化编程任务和代码生成任务非常有用，例如自动生成文本、图像处理代码等。
>
> 综上所述，结合代码解释器使得大模型能够更好地理解和执行代码，从而增强对数学和代码推理的能力。这种能力对于各种编程任务和机器学习任务都具有重要意义。

## 1.4 从模型到应用典型流程

![image-20240329190545629](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329190545629.png)

## 1.5 全链路

![image-20240329190641635](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329190641635.png)

### 1.5.1 数据

![image-20240329190716592](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329190716592.png)

> 数据清洗是数据预处理过程中的一个重要步骤，旨在识别和纠正数据集中的错误、不完整、不准确或不一致的部分。其目的是确保数据集的质量，以便进行后续的分析和建模。
>
> 数据清洗通常涉及以下几个方面的工作：
>
> 1. **缺失值处理：** 发现并处理数据集中的缺失值，可以通过填充、删除或插值等方法来处理缺失值，以确保数据的完整性。
> 2. **异常值处理：** 检测和处理异常值，这些异常值可能会干扰数据分析或建模过程。处理异常值的方法通常包括删除、替换或转换等。
> 3. **重复值处理：** 发现并删除重复的数据记录，以避免对分析结果造成重复计数或偏差。
> 4. **数据格式统一：** 确保数据集中的数据格式一致，例如日期格式、数值格式等，以便后续的数据处理和分析。
> 5. **数据标准化：** 将数据转换为标准的形式，例如将不同单位的数据转换为相同的单位，或将数据缩放到相同的范围内，以便进行比较或建模。
> 6. **数据类型转换：** 将数据转换为正确的数据类型，例如将文本数据转换为数值型数据，以便进行数值计算或建模。
> 7. **一致性检查：** 确保数据集中的数据是一致的，例如同一类别的数据使用相同的命名规范，或者确保数据集中的数据在不同时间点或来源之间是一致的。
>
> 通过进行数据清洗，可以提高数据集的质量和可用性，从而更好地支持数据分析、数据挖掘和机器学习等任务的进行。

### 1.5.2 预训练

![image-20240329191030340](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329191030340.png)

> 大模型的预训练和微调是两种常见的训练策略，它们在使用深度学习模型进行自然语言处理等任务时非常有用。以下是它们的区别与联系：
>
> **预训练（Pre-training）**：
>
> 1. **定义**：预训练是指在大规模的数据集上，使用无监督或半监督的方式，训练一个模型来学习数据中的模式和特征。
> 2. **目的**：主要目的是通过大规模数据的学习，使模型能够获取丰富的语言或领域知识，从而提高模型在各种任务上的性能。
> 3. **例子**：BERT（Bidirectional Encoder Representations from Transformers）是一个典型的预训练模型，它通过在大规模文本数据上进行无监督学习，学习语言表示，然后可以在各种下游任务上进行微调。
>
> **微调（Fine-tuning）**：
>
> 1. **定义**：微调是指在预训练模型的基础上，使用特定任务的标注数据，对模型进行进一步的训练以适应特定任务。
> 2. **目的**：通过微调，可以将预训练模型的学习到的知识迁移到特定任务中，从而加速模型的收敛和提高模型在该任务上的性能。
> 3. **例子**：在自然语言处理任务中，可以将预训练的BERT模型应用于特定的文本分类、命名实体识别等任务，并在这些任务的标注数据上对模型进行微调。
>
> **区别与联系**：
>
> - 区别：预训练是在大规模数据上进行无监督或半监督的学习，目的是学习通用的语言表示；微调是在特定任务的标注数据上对预训练模型进行有监督的进一步训练，以适应特定任务。
> - 联系：微调通常基于预训练的模型进行，预训练的模型可以提供丰富的语言知识和表示，从而加速微调过程并提高模型性能。

### 1.5.3 微调

![image-20240329191250148](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329191250148.png)

![image-20240329191503477](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329191503477.png)

### 1.5.4 评测

![image-20240329191614242](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329191614242.png)

![image-20240329191627594](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329191627594.png)

![image-20240329191651033](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329191651033.png)

![image-20240329191715364](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329191715364.png)

![image-20240329191747176](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329191747176.png)

![image-20240329191818920](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329191818920.png)

![image-20240329191833454](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329191833454.png)

### 1.5.5 部署

![image-20240329191938562](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329191938562.png)

### 1.5.6 智能体

![image-20240329192210158](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329192210158.png)

![image-20240329192233904](C:\Users\chosu\AppData\Roaming\Typora\typora-user-images\image-20240329192233904.png)